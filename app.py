import streamlit as st
from langchain_community.llms import HuggingFaceHub
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

st.title("ğŸ§  ãƒãƒªãƒã‚¿è³ªå•ã‚¢ãƒ—ãƒªï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰LLMï¼‰")

# Hugging Faceã®APIãƒˆãƒ¼ã‚¯ãƒ³ã‚’secretsã‹ã‚‰å–å¾—
HUGGINGFACE_API_TOKEN = st.secrets["HUGGINGFACEHUB_API_TOKEN"]

# ãƒ¢ãƒ‡ãƒ«ã®è¨­å®š
llm = HuggingFaceHub(
    repo_id="google/flan-t5-base",
    model_kwargs={"temperature": 0.5, "max_length": 512},
    huggingfacehub_api_token=HUGGINGFACE_API_TOKEN
)

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
prompt = PromptTemplate(
    input_variables=["question"],
    template="è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ï¼š{question}"
)

chain = LLMChain(llm=llm, prompt=prompt)

query = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
if query:
    with st.spinner("è€ƒãˆä¸­..."):
        answer = chain.run(query)
        st.write("ğŸ§™ å›ç­”ï¼š", answer)